## 运用雅克比和高斯赛德尔公式的求解方程组

## 姓名:陈扬,石晓晨

实验目的：

a. 比较两种方法的收敛速度；

b. 验证收敛条件的正确性。

----

## 雅克比算法

在数值线性代数中，**雅可比法**（Jacobi Method）是一种解对角元素几乎都是各行和各列的绝对值最大的值的线性方程组的算法。求解出每个对角元素并插入近似值。不断迭代直至收敛[[1\]](https://zh.wikipedia.org/wiki/雅可比法#cite_note-ppt-1)。这个算法是[雅可比矩阵](https://zh.wikipedia.org/wiki/雅可比矩阵)的精简版。方法的名字来源于[德国](https://zh.wikipedia.org/wiki/德国)数学家[卡尔·雅可比](https://zh.wikipedia.org/wiki/卡爾·雅可比)。

![image-20190619171006873](http://ww3.sinaimg.cn/large/006tNc79ly1g46kw6cozbj30w20u0jxe.jpg)

```python
# -*- coding: utf-8 -*-
 
#Jacobi迭代法 输入系数矩阵mx、值矩阵mr、迭代次数n、误差c(以list模拟矩阵 行优先)
 
def Jacobi(mx,mr,n=100,c=0.0001):
	if len(mx) == len(mr):  #若mx和mr长度相等则开始迭代 否则方程无解
		x = [] #迭代初值 初始化为单行全0矩阵
		for i in range(len(mr)):
			x.append([0])
		count = 0 #迭代次数计数
		while count < n:
			nx = [] #保存单次迭代后的值的集合
			for i in range(len(x)):
				nxi = mr[i][0]
				for j in range(len(mx[i])):
					if j!=i:
						nxi = nxi+(-mx[i][j])*x[j][0]
				nxi = nxi/mx[i][i]
				nx.append([nxi]) #迭代计算得到的下一个xi值
			lc = [] #存储两次迭代结果之间的误差的集合
			for i in range(len(x)):
				lc.append(abs(x[i][0]-nx[i][0]))
			if max(lc) < c:
				print(count)
				return nx #当误差满足要求时 返回计算结果
			x = nx
			count = count + 1
		return False #若达到设定的迭代结果仍不满足精度要求 则方程无解
	else:
		return False
 
#调用 Jacobi(mx,mr,n=100,c=0.001) 示例
mx = [[8,-3,2],[4,11,-1],[6,3,12]]
 
mr = [[20],[33],[36]]
print(Jacobi(mx,mr,100,0.000001))

```

```
迭代次数 15
[[2.9999999884363877], [1.999999749136996], [0.999999871142208]]
```



---



## **高斯－赛德尔迭代**（**Gauss–Seidel method**）

是[数值线性代数](https://zh.wikipedia.org/wiki/数值线性代数)中的一个[迭代法](https://zh.wikipedia.org/wiki/迭代法)，可用来求出[线性方程组](https://zh.wikipedia.org/wiki/线性方程组)解的近似值。该方法以[卡尔·弗里德里希·高斯](https://zh.wikipedia.org/wiki/卡爾·弗里德里希·高斯)和[路德维希·赛德尔](https://zh.wikipedia.org/w/index.php?title=路德维希·赛德尔&action=edit&redlink=1)命名。同[雅可比法](https://zh.wikipedia.org/wiki/雅可比法)一样，高斯－赛德尔迭代是基于[矩阵分解](https://zh.wikipedia.org/wiki/矩阵分解)原理。

## 算法[[编辑](https://zh.wikipedia.org/w/index.php?title=高斯-赛德尔迭代&action=edit&section=1)]

![image-20190619170945041](http://ww2.sinaimg.cn/large/006tNc79ly1g46kvu1gjjj314c0si7a7.jpg)

```
迭代次数:  15
[[2.9999999884363877], [1.999999749136996], [0.999999871142208]]
```

```python
def gaussSeidel(A, b, x, N, tol):
	maxIterations = 10000
	xprev = [0.0 for i in range(N)]
	for i in range(maxIterations):
		for j in range(N):
			xprev[j] = x[j]
		for j in range(N):
			summ = 0.0
			for k in range(N):
				if (k != j):
					summ = summ + A[j][k] * x[k]
			x[j] = (b[j] - summ) / A[j][j]
		diff1norm = 0.0
		oldnorm = 0.0
		for j in range(N):
			diff1norm = diff1norm + abs(x[j] - xprev[j])
			oldnorm = oldnorm + abs(xprev[j])  
		if oldnorm == 0.0:
			oldnorm = 1.0
		norm = diff1norm / oldnorm
		if (norm < tol) and i != 0:
			print("Sequence converges to [", end="")
			for j in range(N - 1):
				print(x[j], ",", end="")
			print(x[N - 1], "]. \n迭代次数: ", i + 1 )
			return
	print("Doesn't converge.")

guess = [0.0, 0.0 , 0.0 ]
mx = [[8,-3,2],[4,11,-1],[6,3,12]]
mr = [20,33,36]

gaussSeidel(mx,mr, guess,3, 0.000001)
```

```
Sequence converges to [2.9999996835259037 ,2.0000000530966062 ,1.0000001449628966 ]. 
迭代次数:  8
```

## 结论:高斯-赛德尔迭代算法比雅克比迭代算法收敛速度更快