

# 操作系统期末复习要点

> by Marcus·Yang

[toc]

## 第一章

### 非重点

面对对象式 OS

微内核

C/S 模式

网络操作系统

嵌入式操作系统

分布式操作系统

---

### 重点

单批道处理机(早期纸带机)

多批道处理机:后备队列,多道,内存利用率,作业调度

![image-20191221145925061](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-065925.png)

􏲫分时操作系统:交互,共享,即时,时间片,多路性,独立性,及时性,交互性

实时操作系统:立即,可靠性高

---

操作系统基本特征:并发,共享(延伸出虚拟和异步)

操作系统主要功能:软硬件资源管理,用户接口

---

## 第二章(60%)

### 非重点

挂起状态:人为

管程:

进程通信

线程:用户级线程和内核级线程,TCP 管理

---

### 重点

进程的基本概念:进程==程序+数据+PCB,

进程特征:`动态性,并发性,独立性,异步性􏱕`

`进程`是`系统分配调度`的基本单位

前驱图:描述并发执行关系

`顺序执行的特征:顺序性,封闭性,可再现性`

并发执行:间断性(时间片轮转),无封闭性(资源争夺),不可再现性(引入锁的概念)

进程的管理:`PCB`(进程控制块,唯一标志)

基本状态:

1. 就绪,(除 CPU 啥都有了,比如时间片转完了)
2. 执行(获得 CPU)
3. 阻塞,I/O 请求)

---

PCB 块

链接式:依靠指针

索引式:就绪索引表,阻塞索引表,执行指针

---

#### 超级重点

进程同步:并发进程

- 互斥关系-->排他
- 同步关系-->制约,次序

四项基本原则(同步机制需要遵循的原则):

1. 空闲让进：当没有进程处于临界区的时候，应该许可其他进程进入临界区的申请
2. 忙则等待：当前如果有进程处于临界区，如果有其他进程申请进入，则必须等待，保证对临界区的互斥访问
3. 有限等待：对要求访问临界资源的进程，需要在有限时间内进入临界区，防止出现死等
4. 让权等待：当进程无法进入临界区的时候，需要释放处理机，边陷入忙等

经典的进程同步问题：生产者-消费者问题；哲学家进餐问题；读者-写者问题(公交车问题,),打印机问题

#### 老师暗示考哲学家问题

---

#### semaphore

参考:https://www.jianshu.com/p/93128a6cb0f0

---

常用互斥信号量:samephore mutex=1;

#### 1.整型信号量

整型信号量被定义为一个用于表示资源数目的整型量S，它只能被两个标准的原语wait(S)和signal(S)来访问，也可以记为“P操作”和“V操作”。可描述为：

```cpp
 wait(S){
     while (S<=0);
     S=S-1;
 }//p操作
 signal(S){
     S=S+1;
 }//v操作
```

wait操作中，只要信号量S<=0，就会不断地测试。因此，该机制并未遵循“让权等待” 的准则，而是使进程处于“忙等”的状态。

#### 2.记录型信号量

记录型信号量是不存在“忙等”现象的进程同步机制。除了需要一个用于代表资源数目的整型变量value外，再增加一个进程链表L，用于链接所有等待该资源的进程，记录型信号量是由于釆用了记录型的数据结构得名。记录型信号量可描述为：

```cpp
 typedef struct{
     int value;
     struct process *L;
 } semaphore;
```

相应的wait(S)和signal(S)的操作如下：

```csharp
 void wait (semaphore S) { //相当于申请资源
     S.value--;
     if(S.value<0) {
         add this process to S.L;
         block(S.L);
     }
 }
```

wait操作，S.value--，表示进程请求一个该类资源，当S.value<0时，表示该类资源已分配完毕，因此进程应调用block原语，进行自我阻塞，放弃处理机，并插入到该类资源的等待队列S.L中，可见该机制遵循了“让权等待”的准则。

```csharp
 void signal (semaphore S) { //相当于释放资源
     S.value++;
     if(S.value<=0){
         remove a process P from S.L;
         wakeup(P);
     }
 }
```

signal操作，表示进程释放一个资源，使系统中可供分配的该类资源数增1，故S.value++。若加1后仍是S.value<=0，则表示在S.L中仍有等待该资源的进程被阻塞，故还应调用wakeup 原语，将S.L中的第一个等待进程唤醒。

#### 3.AND信号量

上述进程互斥问题都是针对一个临界资源而言的，在有些应用场合，一个进程需要同时获得两个或者更多的资源。AND信号量可以解决多临界资源申请问题。假设有S1，...Sn，N个资源，进程必须申请到所有资源后才可执行，则其wait 和signal描述为：

```cpp
 void wait(S1, S2, ... , Sn){
     if (S1>=1 && S2>=1 && ... && Sn>=1 )
         for (int i=1; i<n; i++)
             Si = Si - 1;
     else 
         place this process//将当前进程放置在第一个不满足Si>=1的阻塞队列中      
 }
 void signal(S1, S2, ... , Sn){
     for (int i=1; i<n; i++)
         Si = Si + 1;
     romove all the process waiting in the queue associated with Si into ready queue
 }
```

#### 4.信号量集

在记录型信号量机制中，wait和signal操作只能进行加一减一的操作。当需要`一次性需要申请N个同类资源`时，需要进行N次操作，这显然是低效的。为方便对资源的控制，每种资源在分配前需要检查其数量是否在其极限值之上。为此，对AND信号量进行扩充。`S为信号量，d为需求量，t为下限值`：

```cpp
 void wait(S1, d1, t1, S2, d2, t2, ... , Sn, dn, tn){
     if (S1>=t1 && S2>=t2 && ... && Sn>=tn )
         for (int i=1; i<n; i++)
             Si = Si - dn;
     else 
         place this process//将当前进程放置在第一个不满足Si>=1的阻塞队列中      
 }
 void signal(S1, d1, S2, d2, ... , Sn, dn,){
     for (int i=1; i<n; i++)
         Si = Si + dn;
     romove all the process waiting in the queue associated with Si into ready queue
       
```

---

#### 1.利用信号量实现同步

信号量机构能用于解决进程间各种同步问题。设S为实现进程P1、P2同步的公共信号量，初值为0。进程P2中的语句y要使用进程P1中语句x的运行结果，所以只有当语句x执行完成之后语句y才可以执行。其实现进程同步的算法如下：

```cpp
 semaphore S = 0; //初始化信号量
 P1 ( ) {
     P1 process
     x; //语句x
     V(S); //告诉进程P2,语句乂已经完成
 }
 P2()）{
     P2 process1
     P(S) ; //检查语句x是否运行完成
     y; // 检查无误，运行y语句
     P2 process2
 }
```

#### 2.利用信号量实现进程互斥

信号量机构也能很方便地解决进程互斥问题。设S为实现进程Pl、P2互斥的信号量，由于每次只允许一个进程进入临界区，所以S的初值应为1（即可用资源数为1)。只需把临界区置于P(S)和V(S)之间，即可实现两进程对临界资源的互斥访问。其算法如下：

```cpp
 semaphore S = 1; //初化信号量
 P1 ( ) {
     P1 process1
     P(S); // 准备开始访问临界资源，加锁
     // 进程P1的临界区
     V(S); // 访问结束，解锁
     P1 process2
 }
 P2() {
     P2 process1
     P(S); //准备开始访问临界资源，加锁
     // 进程P2的临界区；
     V(S); // 访问结束，解锁
     P2 process2
 }
```

#### 3.利用信号量实现前驱关系

信号量也可以用来描述程序之间或者语句之间的前驱关系。下图给出了一个前驱图，其中S1, S2, S3, …, S6是最简单的程序段。为保证S1 -> S2、 S1 -> S3、 S2 -> S4、S2 ->S5、S3 -> S6、S4 -> S6、S5 -> S6等前驱关系需要设置信号量a1、a2、bl、b2、c、d、e，并初始化为0。

![image-20191221152439680](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-072440.png)

实现算法如下：

```cpp
semaphore al=a2=bl=b2=c=d=e=0; //初始化信号量
 S1() {
     S1 process
     V(al); V(a2) ; //S1已经运行完成
 }
 S2() {
     P(a1); //检查S1是否运行完成
     S2 process
     V(bl); V(b2); // S2已经运行完成
 }
 S3() {
     P(a2); //检查S1是否已经运行完成
     S3 process
     V(c); //S3已经运行完成
 }
 S4() {
     P(b1); //检查S2是否已经运行完成
     S4 process
     V(d); //S4已经运行完成
 }
 S5() {
     P(b2); //检查S2是否已经运行完成
     S5 process
     V(e); // S5已经运行完成
 }
 S6() {
     P(c); //检查S3是否已经运行完成
     P(d); //检查S4是否已经运行完成
     P(e); //检查S5是否已经运行完成
     S6 process
 }
```

---

打印机问题:

SA=0,SB=0

![image-20191221153017783](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-073018.png)

---

剪切板复制模型

![image-20191221153252414](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-073252.png)

---

#### 超级重点

#### 生产者消费者模型

一组生产者进程和一组消费者进程共享一个初始为空、大小为n的缓冲区，只有缓冲区没满时，生产者才能把消息放入到缓冲区，否则必须等待；只有缓冲区不空时，消费者才能从中取出消息，否则必须等待。由于缓冲区是临界资源，它只允许一个生产者放入消息，或者一个消费者从中取出消息。

- 生产者和消费者对缓冲区互斥访问是互斥关系，同时生产者和消费者又是一个相互协作的关系，只有生产者生产之后，消费者才能消费，他们也是同步关系。

- 信号量mutex作为互斥信号量，它用于控制互斥访问缓冲池，互斥信号量初值为1；信号量full用于记录当前缓冲池中“满”缓冲区数，初值为0。信号量empty 用于记录当前缓冲池中“空”缓冲区数，初值为n。

1. empty=n,mutex=1,full=0
2. AND 信号量
3. ![image-20191221154117050](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-074117.png)

---

#### 哲学家进餐

要求会用两种算法

(1) 仅当哲学家的左、右两只筷子均可用时，才允许他拿起子进餐

(2) 至多只允许有四位哲学家同时去拿左边的

(3) 拠定奇数号哲学家先拿他左边的筷子，然后再去拿右边的镁子；而偶数号哲学家则相反。

(4) 利用 AND 信号量机制解决哲学家进餐问题

```c
semaphore chopstick[5] = {1,1,1,1,1}; //初始化信号量
semaphore mutex=l;  //设置取筷子的信号量
Pi(){ //i号哲学家的进程
    do{
        P (mutex) ; //在取筷子前获得互斥量
        P (chopstick [i]) ; //取左边筷子
        P (chopstick[ (i+1) %5]) ;  //取右边筷子
        V (mutex) ; //释放取筷子的信号量
        eat;  //进餐
        V(chopstick[i] ) ;  //放回左边筷子
        V(chopstick[ (i+l)%5]) ;  //放回右边筷子
        think;  // 思考
    }while(1);
}
```



---

#### 读者写者问题

参考:http://c.biancheng.net/cpp/html/2601.html

①允许多个读者可以同时对文件执行读操作；

②只允许一个写者往文件中写信息；

③任一写者在完成写操作之前不允许其他读者或写者工作；

④写者执行写操作前，应让已有的读者和写者全部退出。

分析读者和写者是互斥的，写者和写者也是互斥的，而读者和读者不存在互斥问题。

读者优先:

```c
int count=0;  //用于记录当前的读者数量
semaphore mutex=1;  //用于保护更新count变量时的互斥
semaphore rw=1;  //用于保证读者和写者互斥地访问文件
writer () {  //写者进程
    while (1){
        P(rw); // 互斥访问共享文件
        Writing;  //写入
        V(rw) ;  //释放共享文件
    }
}

reader () {  // 读者进程
    while(1){
        P (mutex) ;  //互斥访问count变量
        if (count==0)  //当第一个读进程读共享文件时
            P(rw);  //阻止写进程写
        count++;  //读者计数器加1
        V (mutex) ;  //释放互斥变量count
        reading;  //读取
        P (mutex) ;  //互斥访问count变量
        count--; //读者计数器减1
        if (count==0)  //当最后一个读进程读完共享文件
            V(rw) ;  //允许写进程写
        V (mutex) ;  //释放互斥变量 count
    }
}
```

写着优先:

```c
int count = 0;  //用于记录当前的读者数量
semaphore mutex = 1;  //用于保护更新count变量时的互斥
semaphore rw=1;  //用于保证读者和写者互斥地访问文件
semaphore w=1;  //用于实现“写优先”

writer(){
    while(1){
        P(w);  //在无写进程请求时进入
        P(rw);  //互斥访问共享文件
        writing;  //写入
        V(rw);  // 释放共享文件
        V(w) ;  //恢复对共享支件的访问
    }
}

reader () {  //读者进程
    while (1){
        P (w) ;  // 在无写进程请求时进入
        P (mutex);  // 互斥访问count变量

        if (count==0)  //当第一个读进程读共享文件时
            P(rw);  //阻止写进程写

        count++;  //读者计数器加1
        V (mutex) ;  //释放互斥变量count
        V(w);  //恢复对共享文件的访问
        reading;  //读取
        P (mutex) ; //互斥访问count变量
        count--;  //读者计数器减1

        if (count==0)  //当最后一个读进程读完共享文件
            V(rw);  //允许写进程写

        V (mutex);  //释放互斥变量count
    }
}
```

---

#### 吸烟者问题(我❤️这个问题)

假设一个系统有三个抽烟者进程和一个供应者进程。每个抽烟者不停地卷烟 并抽掉它，但是要卷起并抽掉一支烟，抽烟者需要有三种材料：烟草、纸和胶水。三个抽烟 者中，第一个拥有烟草、第二个拥有纸，第三个拥有胶水。供应者进程无限地提供三种材料， 供应者每次将两种材料放到桌子上，拥有剩下那种材料的抽烟者卷一根烟并抽掉它，并给供 应者一个信号告诉完成了，供应者就会放另外两种材料在桌上，这种过程一直重复（让三个 抽烟者轮流地抽烟)。

- 供应者与三个抽烟者分别是同步关系。由于供应者无法同时满足两个或 以上的抽烟者，三个抽烟者对抽烟这个动作互斥
- 四个进程。供应者作为生产者向三个抽烟者提供材料。
- 信号量offer1、offer2、offer3分别表示烟草和纸组合的资源、烟草和 胶水组合的资源、纸和胶水组合的资源。信号量finish用于互斥进行抽烟动作。

```c
int random; //存储随机数
semaphore offer1=0; //定义信号量对应烟草和纸组合的资源
semaphore offer2=0; //定义信号量对应烟草和胶水组合的资源
semaphore offer3=0; //定义信号量对应纸和胶水组合的资源
semaphore finish=0; //定义信号量表示抽烟是否完成

//供应者
while(1){
    random = 任意一个整数随机数;
    random=random% 3;
    if(random==0)
        V(offerl) ; //提供烟草和纸
    else if(random==l) 
        V(offer2);  //提供烟草和胶水
    else
        V(offer3)  //提供纸和胶水
    // 任意两种材料放在桌子上;
    P(finish);
}

//拥有烟草者
while(1){
    P (offer3);
    // 拿纸和胶水，卷成烟，抽掉;
    V(finish);
}

//拥有纸者
while(1){
    P(offer2);
    // 烟草和胶水,卷成烟，抽掉；
    V(finish);
}

//拥有胶水者
while(1){
    P(offer1);
    // 拿烟草和纸，卷成烟，抽掉;
    v(finish);
}
```



---

## 第三章

必考银行家算法

### 非重点

作业:作业一是用户在一次上机活动中，请求计算机系统所做的系列工作的集合（也称任务)

作业状态:进入,后备,运行,完成.

![image-20191221164135420](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-084135.png)

调度模型:

- 仅进程调度
- 高低级调度模型
- 三级调度模型



----

### 重点

#### 调度算法

- FCFS 先到先服务(非剥夺)
- SJF 短作业优先(长作业饥饿)
- HPF 最高优先权
- RR 时间片轮转(太大退化 FCFS,太小系统开销大)
- (非重点)多级反馈调度模型

![image-20191221164556442](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-084557.png)

周转时间=完成时间-到达时间

带权周转时间=周转时间/服务时间

抢占式和非抢占式(实时性更好)

- 实时调度(理解即可)

---

#### 死锁(银行家算法,必考)

死锁原因：

1. 竞争资源：请求同一有限资源的进程数多于可用资源数
2. 进程推进顺序非法：进程执行中，请求和释放资源顺序不合理，如资源等待链

死锁产生的必要条件：

1. 互斥条件:进程对所分配的资源进行排他性的使用
2. 请求和保持条件：进程被阻塞的时候并不释放锁申请到的资源
3. 不可剥夺条件：进程对于已经申请到的资源在使用完成之前不可以被剥夺
4. 环路等待条件：发生死锁的时候存在的一个 进程-资源 环形等待链

死锁处理：

1. 预防死锁：破坏产生死锁的4个必要条件中的一个或者多个；实现起来比较简单，但是如果限制过于严格会降低系统资源利用率以及吞吐量(AND 信号量机制,浪费资源)
2. 避免死锁：在资源的动态分配中，防止系统进入不安全状态(可能产生死锁的状态)-如`银行家算法`(安全序列)
3. 检测死锁：允许系统运行过程中产生死锁，在死锁发生之后，采用一定的算法进行检测，并确定与死锁相关的资源和进程，采取相关方法清除检测到的死锁。实现难度大
4. 解除死锁：与死锁检测配合，将系统从死锁中解脱出来（撤销进程或者剥夺资源）。对检测到的和死锁相关的进程以及资源，通过撤销或者挂起的方式，释放一些资源并将其分配给处于阻塞状态的进程，使其转变为就绪态。实现难度大
    - 资源剥夺
    - 撤销进程
    - 进程回退

死锁定理：S为死锁状态的充分条件是，当且仅当S的资源分配图是不能完全简化的

化简方法:https://blog.csdn.net/coding1994/article/details/52474731

死锁一定有环

---

2<=k<=n

资源:可剥夺(CPU,内存),不可剥夺(打印机),永久性,临时性(一次性)

k 个进程长期僵持

若 n 个进程,m 个资源,每个进程 a 个资源,则
$$
(a-1)n+1<=m \;,时不发生死锁\\
n<=\frac{m-1}{a-1}
$$

---

安全序列:

- 按某种顺序并发进程都能达到获得最大姿资源而顺序完成的序列为安全序列

- 能到安全序列的状态为安全状态

---

#### 银行家算法:(课后题)

银行家算法的主要思想是避免系统进入不安全状态。在每次进行资源分配时，它首先检查系统是否有足够的资源满足要求，如果有，则先进行分配，并对分配后的新状态进行安全性检查。如果新状态安全，则正式分配上述资源，否则就拒绝分配上述资源。这样，它保证系统始终处于安全状态，从而避免死锁现象的发生。

假定系统中有5个进程{P0, P1, P2, P3, P4}和三类资源{A, B, C}，各种资源的数量分别为10、5、7，在T0时刻的资源分配情况见表2-16。
**1) T0时刻的安全性。**利用安全性算法对T0时刻的资源分配进行分析，由表2-17可知，在T0时刻存在着一个安全序列{P1, P3, P4, P2, P0}，故系统是安全的。

- Request1(1, 0, 2) <= Need1(l, 2, 2)。
- Request1(1, 0, 2) <= Available1(3, 3, 2)。
- 系统先假定可为P1分配资源，并修改Available、Allocation1和Need1矢量，由此形成的资源变化情况见表2-18。
- 再利用安全性算法检查此时系统是否安全。

| 进程 / 资源情况 | Work A  B  C | Need A  B  C | Allocation A  B  C | Work+ Allocation A  B  C | Finish |
| --------------- | ------------ | ------------ | ------------------ | ------------------------ | ------ |
| P1              | 2  3  0      | 0  2  0      | 3  0  2            | 5  3  2                  | true   |
| P3              | 5  3  2      | 0  1  1      | 2  1  1            | 7  4  3                  | true   |
| P4              | 7  4  3      | 4  3  1      | 0  0  2            | 7  4  5                  | true   |
| P0              | 7  4  5      | 7  4  3      | 0  1  0            | 7  5  5                  | true   |
| P2              | 7  5  5      | 6  0  0      | 3  0  2            | 10  5  7                 | true   |


**3) P4请求资源**P4发出请求矢量Request4(3, 3, 0)，系统按银行家算法进行检查：

- Request0(0, 2, 0) <= Need0(7, 4, 3)。
- Request0(0, 2, 0) <= Available(2, 3, 0)。
- 系统暂时先假定可为P0分配资源，并修改有关数据，见表2-19。

| 进程 / 资源情况 | Allocation A  B  C | Need A  B  C | Available A  B  C |
| --------------- | ------------------ | ------------ | ----------------- |
| P0              | 0  3  0            | 7  2  3      | 2  1  0           |
| P1              | 3  0  2            | 0  2  0      |                   |
| P2              | 3  0  2            | 6  0  0      |                   |
| P3              | 2  1  1            | 0  1  1      |                   |
| P4              | 0  0  2            | 4  3  1      |                   |


**5) 进行安全性检测。**可用资源Available(2, 1, 0)已不能满足任何进程的需要，故系统进入不安全状态，此时系统不分配资源。

---

## 第四章

存储管理重点

内存管理的主要任务是为`多道程序`的运行提供良好的环境.
储存管理应该有的功能:

1. 内存管理方式
2. 实现内存的分配和回收
3. 地址变换
4. “扩充”内存容量-->虚拟
5. 存储保护-->权限

---

### 非重点

程序是如何在内存中运行的?

A:(1)编译 (2)链接 (3)装入 

装入:绝对(单道),可重定位(地址变换,逻辑-->物理,多道),动态装入(运行时,可重定位寄存器)

链接:静态(不共享),装入时动态(共享,更新),运行时动态(节省空间)

---

解决碎片的方法:移动、重定位、合并。把多个小分区拼成一个大分区

分区保护:**界限寄存器方法** ,**存储保护键方法** 

---

快表访问时间计算

![image-20191221142002444](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-062003.png)

---

请求分页式:

**抖动现象** **一个页面经常换进换出** 

![image-20191221143845161](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-063845.png)

---

请求分段式

没例题不考

---

### 重点

#### 连续分配存储管理方式 

单用户,程序一次性,整体性装入,连续开辟内存空间

细分:

1. 单一连续分配方式
2. 固定读取分配方式
3. 动态分区很分配方式
4. 动态重定位分区分配方式

---

#### 单一连续分配方式 

单用户、单任务

分为系统区和用户区

静态分配方式

浪费内存空间

![image-20191221133042442](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-055028.png)

---

#### 分区分配方式存储管理

多道程序 ,将内存分成若干个分区(大小相等/不相等) 

细分:

- 􏱖固定分区存储管理 :大小可以相等，也可以不等大小及边界在运行时不能改变,建立分区表

    ![image-20191221135352546](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-055352.png)

    管理简单，但一部分存储空间被浪费。主存的利用率不高。

- 动态分区存储管理 :可变式分区,大小可变,分区数目可变

    数据结构:空闲分区表,空闲分区链

---

#### 分区分配算法 

- 􏱘**首次适应算法** 􏱘
- **循环首次适应算法**
-  􏱘**最佳适应算法**
-  􏱘**最坏适应算法** 

----

􏱘**首次适应算法** 􏱘:

每次从小到大找,看当前分区是否满足大小,若满足这放入

![image-20191221135707419](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-055707.png)

---

循环首次适应算法 

每次从上一个找到的分区(不包括当前)开始递增找,看当前分区是否满足大小,若满足这放入

![image-20191221135820804](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-055821.png)

---

最佳适应算法 

空闲分区表/链按容量大小递增的次序排列(每次都要按大小排序)

空闲分区表/链的首开始

很多碎片

![image-20191221135948205](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-055948.png)

---

最坏适应算法 

空闲分区表/链按容量大小递减的次序排列(每次都要按大小排序)

空闲分区表/链的首开始

大作业可能不能得到满足

![image-20191221140139211](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-060140.png)

----

#### 回收分区的四种情况:(简答题必考)

![image-20191221140355144](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-060355.png)

块数和起始地址都不变:上有下无

---

#### 超级重点:

基本:一次性装入

请求:虚拟(覆盖,交换)

连续:产生许多碎片,拼接紧凑技术,

离散:基本分页,基本分段,段页式(基本单位是段、页 ),避免拼接

缓存:增加匹配速度,提高并行程度

离散存储管理方式:整体性、一次性、离散性 

---

#### 究极重点

##### 基本分页存储 :

一维

逻辑空间从0开始

内存空间:与页大小相等,`块大小等于页大小`

页面大小:2 的幂,512B~8KB

![image-20191221141237025](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-061237.png)

**页内碎片:最后一页装不满一块 出现** 

碎片最少的方法

页表:页表寄存器,[页表始址|页表长度]

必考题型:

![image-20191221141448337](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-061449.png)

地址变换(简答题)

就是把页号换成块号(要检测是否合法)

![image-20191221141752294](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-061752.png)

快表(老师好像说考):

CPU访问一个字节的数据需两次访问内存)

联想寄存器、联想存储器、TLB

---

##### 基本分段式

结论:基本分页式管理不利于共享 实现数据共享的最好方法-->段式存储管理

二维

段表:[**段名|段内偏移量** ]

内存分配:以段为单位，分配一段连续的物理地址空间;段间不必连续

碎片多

CPU 访问两次

![image-20191221142346360](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-062346.png)

40K<2^16,所以段内地址为 16bit

590<2^10,所以段内地址为 10bit

2-->90<120,越界

0-->500>430-->210+430=640

答案写了个陀螺啊

---

上课说的重点:

基本分页和基本分段存储管理方式的主要区别

![image-20191221143424285](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-063425.png)

----

##### 段页式(考大题太难了,所以不考)

结合了两者(但是碎片并不是最少的)

cpu 访问 3 次

每个进程一张段表,每个段一张页表.

段表含段号,页表始址和页表长度.页表含页号和块号. 

---

虚拟存储器:离散,部分性,多次性,逻辑上增加了内存

时间局部性

空间局部性

特点:带请求两个字

---

页面置换算法(大题1)

- 最佳置换算法(上帝视角-->预测未来)
- ![image-20191221144447487](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-064448.png)
- FCFS(先进先出(跳空))
- ![image-20191221144747441](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-064747.png)
- LRU(考点(不跳空))
- ![image-20191221144825191](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-064825.png)



---

## 第五章

I/O 系统 

缓冲技术:匹配速度,提高并行程度

分类:**单缓冲; 双缓冲;多缓冲:循环缓冲、缓冲池** 

#### 必考

#### Spooling简答

spooling 假脱机技术--> 虚拟,用户进程分配到实际的是硬盘上开辟的一块存储区域

![image-20200108162301168](https://cy-1256894686.cos.ap-beijing.myqcloud.com/2020-01-08-082301.png)

![image-20200108162106125](https://cy-1256894686.cos.ap-beijing.myqcloud.com/2020-01-08-082107.png)

输入井和输出井

在磁盘上开辟出的两个存储区域。输入井模拟脱机输入时的磁盘，用于收容I/O设备输 入的数据。输出井模拟脱机输出时的磁盘，用于收容用户程序的输出数据。

![img](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-092911.jpg)

输入进程模拟脱机输入时的外围控制机，将用户要求的数据从输入机通过输入缓冲区再 送到输入井。当CPU需要输入数据时，直接将数据从输入井读入内存。输出进程模拟脱机 输出时的外围控制机，把用户要求输出的数据先从内存送到输出并，待输出设备空闲时，再 将输出井中的数据经过输出缓冲区送到输出设备。

- 在联机情况下实现的同时外围操作称为SPOOLING技术
- 设备无关性策略
- 虚拟设备
- 提升I/O
- 独占变共享

---

磁盘结构:柱面、磁道、扇区

**磁盘物理块的地址:柱面号 磁头号 扇区号** 

---

#### 磁盘调度算法

看图看一遍就理解了,很简单的

- FCFS(算`差`就行)
- SSTF 最短寻道时间优先算法(从当前位置开始,每次找最近的)
- SCAN 扫描算法(从当前位置从小到大,再回过头从大到小)(反过来也行)
- CSCAN 循环扫描算法(从当前位置从小到大,再回到最下的位置开始从小到大到当前位置)

背例题就行,考的很简单的

![image-20191221171833873](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-091834.png)

![image-20191221172216994](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-092217.png)

![image-20191221172314702](https://cy-1256894686.cos.ap-beijing.myqcloud.com/cy/2019-12-21-092315.png)

---

## 第六章

文件系统

没听课,等老师划重点吧



---

## 第七章

考 tm



---

## 第八章

没听课,别瞎想了后面都不考了





## 简答题汇总

## 操作系统的基本特征

- 并发：同一段时间内多个程序执行(注意区别并发和并行，前者是同一时刻的多个事件，后者是统一时间段内的多个事件)
- 共享：系统中的资源可以被内存中多个并发执行的进线程共同使用
    - 虚拟：通过时分复用（如分时系统）以及空分复用（如虚拟内存）技术实现把一个物理实体虚拟为多个
    - 异步：系统中的进程是以走走停停的方式执行的，且以一种不可预知的速度推进

## 操作系统的主要功能

- 处理机管理：处理机分配都是以进程为单位，所以处理机管理也被看做是进程管理。包括进程控制，进程同步，进程通信和进程调度
- 存储器管理（或者内存管理）：内存分配，内存保护，地址映射，内存扩充
- 设备管理：管理所有外围设备，包括完成用户的IO请求；为用户进程分配IO设备；提高IO设备利用率；提高IO速度；方便IO的使用
- 文件管理：管理用户文件和系统文件，方便使用同时保证安全性。包括：磁盘存储空间管理，目录管理，文件读写管理以及文件共享和保护
    提供用户接口：程序接口（如API）和用户接口（如GUI）

## 进程和线程的区别

进程：进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位（具有动态、并发、独立、异步的特性，以及就绪、执行、阻塞3种状态；也有5状态或者7状态；资源拥有单位的属性）；引入进程是为了使多个程序可以并发的执行，以提高系统的资源利用率和吞吐量。

线程：是比进程更小的可独立运行的基本单位，可以看做是轻量级的进程（具有轻型实体，独立调度分派单位，可并发执行，共享进程资源等属性）；引入目的是为了减少程序在并发执行过程中的开销，使OS的并发效率更高。

两者的对比：

1. 调度方面：在引入线程的OS中，线程是独立的调度和分派单位，而进程作为资源的拥有单位(相当于把未引入线程的传统OS中的进程的两个属性分开了)。由于线程不拥有资源，因此可以显著的提高并发度以及减少切换开销。
2. 并发性：引入了线程的OS中，进程间可以并发，而且一个进程内部的多个线程之间也是可以并发的，这就使OS具有更好的并发性，有效的提高了系统资源利用率和吞吐量。
3. 拥有资源：无论OS是否支持线程，进程都是基本的资源拥有单位，线程只拥有很少的基本的资源，但是线程可以访问所隶属的进程的资源（进程的代码段，数据段和所拥有的系统资源如fd）
4.  系统开销：创建或者撤销进程的时候，系统要为之创建或回收PCB，系统资源等，切换时也需要保存和恢复CPU环境。而线程的切换只需要保存和恢复少量的寄存器，不涉及存储器管理方面的工作，所以开销较小。此外，统一进程中的多个线程由于共享地址空间，所以通信同步等都比较方便。

## 进程的几种状态

主要是3种基本状态

1. 就绪状态：进程获得了除了CPU之外的所有的必要资源，只要获得CPU就可以立即执行，此时的进程处于就绪态

2. 执行状态：进程已经获得CPU，正在运行，在多处理其系统中，会有多个进程同时处于运行状态

3. 阻塞状态：处于执行状态的进程由于发生某些事件而暂时无法继续执行，放弃处理机而处于暂停状态，此时进程就处于阻塞（执行受到阻塞）状态 

就绪->执行：调度进程为其分配了处理机
执行->就绪：时间片用完
执行->阻塞：申请临界资源而未被满足，如IO请求或者申请缓存
阻塞->就绪：请求得到满足，如IO完成

## 进程同步

- 多进程虽然提高了系统资源利用率和吞吐量，但是由于进程的异步性可能造成系统的混乱。进程同步的任务就是对多个相关进程在执行顺序上进行协调，使并发执行的多个进程之间可以有效的共享资源和相互合作，保证程序执行的可再现性

同步机制需要遵循的原则：

1. 空闲让进：当没有进程处于临界区的时候，应该许可其他进程进入临界区的申请
2. 忙则等待：当前如果有进程处于临界区，如果有其他进程申请进入，则必须等待，保证对临界区的互斥访问
3. 有限等待：对要求访问临界资源的进程，需要在有限时间呃逆进入临界区，防止出现死等
4. 让权等待：当进程无法进入临界区的时候，需要释放处理机，边陷入忙等

经典的进程同步问题：生产者-消费者问题；哲学家进餐问题；读者-写者问题

## 进程间通信

进程通信就是指进程间的信息交换，交换信息可以使一个状态，也可以是很多的byte。进程间同步互斥也存在信息的交换，因此也属于是一种IPC，属于是低级通信。该低级通信存在的问题：

1）通信的数据量太少
2）通信对用户不透明(数据的传递或者同步互斥都需要程序员实现)

高级通信机制（高级通信的通信细节被OS隐藏，因此使用起来增加方便而且可以传送大量的数据，尤其是管道通信）：

1. 共享存储器系统：相互通信的进程共享某些数据结构或者是存储区，进程之间可以通过这些共享空间进行通信。分为：

    1）基于共享数据结构的通信，如生产者消费者系统中的有界缓冲区；
    2）基于共享存储区的通信，可以传输大量数据，通信的进程之间可以像读写普通存储器一样读写共享存储区

2. 消息传递系统：进程间通信采用的是格式化的消息，可以直接使用OS提供的消息发送或者接受原语进行通信。由于隐藏了通信细节，所以简化了通信程序的复杂性

3. 管道通信：管道是连接两个一个读进程和一个写进程之间用于实现数据交换的一个共享文件。为了协调管道通信双方，需要管道机制实现如下功能：

    1）互斥：统一时刻只能有一个进程对管道进行读写；
    2）同步：当读端发现管道为空的时候需要睡眠等待，直到有数据时候被唤醒，相应的写端也是在管道已满的时候等待直到被唤醒；
    3）确定对方的存在性：只有同时有读端和写端，管道才有存在意义

## 进程/任务调度算法

基本调度算法：

1. 先来先服务调度算法FCFS：既可以作为作业调度算法也可以作为进程调度算法；按作业或者进程到达的先后顺序依次调度；因此对于长作业比较有利；
2. 短作业优先调度算法SJ(P)F：作业调度算法，算法从就绪队列中选择估计时间最短的作业进行处理，直到得出结果或者无法继续执行；缺点：不利于长作业；未考虑作业的重要性；运行时间是预估的，并不靠谱
3. 高优先权优先调度算法HPF：既可以作为作业调度也可以作为进程调度算法；调度作业时，从就绪队列中选择优先级最高的作业进行处理；由于涉及到了优先级，因此可以分为抢占式和非抢占式；而且优先级的确定也可以分为静态优先级（事先根据进程类型，进程对资源的需求，用户要求等方面确定一个固定值）；动态优先级（随进程的推进或者等待时间而增加或者减少）
4. 高相应比算法HRN：响应比=(等待时间+要求服务时间)/要求服务时间；
5. 时间片轮转调度RR：按到达的先后对进程放入队列中，然后给队首进程分配CPU时间片，时间片用完之后计时器发出中断，暂停当前进程并将其放到队列尾部，循环
6. 多级反馈队列调度算法：目前公认较好的调度算法；设置多个就绪队列并为每个队列设置不同的优先级，第一个队列优先级最高，其余依次递减。优先级越高的队列分配的时间片越短，进程到达之后按FCFS放入第一个队列，如果调度执行后没有完成，那么放到第二个队列尾部等待调度，如果第二次调度仍然没有完成，放入第三队列尾部…。只有当前一个队列为空的时候才会去调度下一个队列的进程。

实时调度算法：

1. 最早截止时间优先调度算法EDF：算法根据任务的开始截止时间确定优先级，截止时间越早，优先级越高。算法维护一个实时就绪队列，最早截止时间的任务排在最前面；可以用于抢占式调度也可以用于非抢占式调度；
2. 最低松弛度优先调度算法LLF：松弛度=(必须完成时间-本身运行时间-当前时间);算法根据任务的松弛度确定任务的优先级，松弛度代表了任务的紧急程度，任务的紧急程度越高，被赋予的优先级越高

## 死锁的必要条件以及处理方式

死锁是指多个进程在运行过程中，因为争夺资源而造成的一种僵局，如果没有外力推进，处于僵局中的进程就无法继续执行。

死锁原因：

1. 竞争资源：请求同一有限资源的进程数多于可用资源数
2. 进程推进顺序非法：进程执行中，请求和释放资源顺序不合理，如资源等待链

死锁产生的必要条件：

1. 互斥条件:进程对所分配的资源进行排他性的使用
2. 请求和保持条件：进程被阻塞的时候并不释放锁申请到的资源
3. 不可剥夺条件：进程对于已经申请到的资源在使用完成之前不可以被剥夺
4. 环路等待条件：发生死锁的时候存在的一个 进程-资源 环形等待链

死锁处理：

1. 预防死锁：破坏产生死锁的4个必要条件中的一个或者多个；实现起来比较简单，但是如果限制过于严格会降低系统资源利用率以及吞吐量
2. 避免死锁：在资源的动态分配中，防止系统进入不安全状态(可能产生死锁的状态)-如银行家算法
3. 检测死锁：允许系统运行过程中产生死锁，在死锁发生之后，采用一定的算法进行检测，并确定与死锁相关的资源和进程，采取相关方法清除检测到的死锁。实现难度大
4. 解除死锁：与死锁检测配合，将系统从死锁中解脱出来（撤销进程或者剥夺资源）。对检测到的和死锁相关的进程以及资源，通过撤销或者挂起的方式，释放一些资源并将其分配给处于阻塞状态的进程，使其转变为就绪态。实现难度大

死锁定理：S为死锁状态的充分条件是，当且仅当S的资源分配图是不能完全简化的

## 内存管理方式-段式页式和段页式

由于连续内存分配方式(单一连续分配，固定分区分配，动态分区分配，动态重定位分区分配)导致的内存利用率偏低以及内存碎片的问题，进而引出离散的内存分配方式。离散内存分配可以从OS的内存管理角度引出页式(离散分配的基本单位是页)管理，也可以从程序编制角度引出段式(离散分配的基本单位是段)管理。

### 基本分页存储管理

- 基本分页存储管理中不具备页面置换功能(即没有实现虚拟内存的功能)，因此需要整个程序的所有页面都装入内存之后才可以运行。因为程序数据存储在不同的页面中，而页面又离散的分布在内存中，因此需要一个页表来记录逻辑地址和实际存储地址之间的映射关系，以实现从页号到物理块号的映射。由于页表也是存储在内存中的，因此和不适用分页管理的存储方式相比，访问分页系统中内存数据需要两次的内存访问(一次是从内存中访问页表，从中找到指定的物理块号，加上页内偏移得到实际物理地址；第二次就是根据第一次得到的物理地址访问内存取出数据)。
- 为了减少两次访问内存导致的效率影响，分页管理中引入了快表(或者联想寄存器)机制，包含快表机制的内存管理中，当要访问内存数据的时候，首先将页号在快表中查询，如果查找到说明要访问的页表项在快表中，那么直接从快表中读取相应的物理块号；如果没有找到，那么访问内存中的页表，从页表中得到物理地址，同时将页表中的该映射表项添加到快表中(可能存在快表换出算法)。
    在某些计算机中如果内存的逻辑地址很大，将会导致程序的页表项会很多，而页表在内存中是连续存放的，所以相应的就需要较大的连续内存空间。为了解决这个问题，可以采用两级页表或者多级页表的方法，其中外层页表一次性调入内存且连续存放，内层页表离散存放。相应的访问内存页表的时候需要一次地址变换，访问逻辑地址对应的物理地址的时候也需要一次地址变换，而且一共需要访问内存3次才可以读取一次数据。

### 基本分段存储管理方式

- 分页是为了提高内存利用率，而分段是为了满足程序员在编写代码的时候的一些逻辑需求(比如数据共享，数据保护，动态链接等)。
    分段内存管理当中，地址是二维的，一维是段号，一维是段内地址；其中每个段的长度是不一样的，而且每个段内部都是从0开始编址的。由于分段管理中，每个段内部是连续内存分配，但是段和段之间是离散分配的，因此也存在一个逻辑地址到物理地址的映射关系，相应的就是段表机制。段表中的每一个表项记录了该段在内存中的起始地址和该段的长度。段表可以放在内存中也可以放在寄存器中。
    访问内存的时候根据段号和段表项的长度计算当前访问段在段表中的位置，然后访问段表，得到该段的物理地址，根据该物理地址以及段内偏移量就可以得到需要访问的内存。由于也是两次内存访问，所以分段管理中同样引入了联想寄存器。

分段和分页的对比：

1. 页是信息的物理单位，是出于系统内存利用率的角度提出的离散分配机制；段是信息的逻辑单位，每个段含有一组意义完整的信息，是出于用户角度提出的内存管理机制
2. 页的大小是固定的，由系统决定；段的大小是不确定的，由用户决定
3. 页地址空间是一维的，段地址空间是二维的

### 段页式存储管理

- 先将用户程序分为若干个段，然后再把每个段分成若干个页，并且为每一个段赋予一个段名称。这样在段页式管理中，一个内存地址就由段号，段内页号以及页内地址三个部分组成。
- 段页式内存访问：系统中设置了一个段表寄存器，存放段表的起始地址和段表的长度。地址变换时，根据给定的段号（还需要将段号和寄存器中的段表长度进行比较防止越界）以及寄存器中的段表起始地址，就可以得到该段对应的段表项，从段表项中得到该段对应的页表的起始地址，然后利用逻辑地址中的段内页号从页表中找到页表项，从该页表项中的物理块地址以及逻辑地址中的页内地址拼接出物理地址，最后用这个物理地址访问得到所需数据。由于访问一个数据需要三次内存访问，所以段页式管理中也引入了高速缓冲寄存器。

## 虚拟内存及页面置换算法

- 如果存在一个程序，所需内存空间超过了计算机可以提供的实际内存，那么由于该程序无法装入内存所以也就无法运行。单纯的增加物理内存只能解决一部分问题，但是仍然会出现无法装入单个或者无法同时装入多个程序的问题。但是可以从逻辑的角度扩充内存容量，即可解决上述两种问题。

- 虚拟存储器就是具有请求调入功能和置换功能，可以从逻辑上对内存容量加以扩充的一种存储器系统。虚拟存储器都是建立在离散内存管理的基础上

虚拟存储器的特征：

1. 多次性：一个作业可以分多次被调入内存。多次性是虚拟存储特有的属性
2. 对换性：作业运行过程中存在换进换出的过程(换出暂时不用的数据换入需要的数据)
3. 虚拟性：虚拟性体现在其从逻辑上扩充了内存的容量(可以运行实际内存需求比物理内存大的应用程序)。虚拟性是虚拟存储器的最重要特征也是其最终目标。虚拟性建立在多次性和对换性的基础上行，多次性和对换性又建立在离散分配的基础上

### 页面置换算法

1. 最佳置换算法：只具有理论意义的算法，用来评价其他页面置换算法。置换策略是将当前页面中在未来最长时间内不会被访问的页置换出去。
    先进先出置换算法：简单粗暴的一种置换算法，没有考虑页面访问频率信息。每次淘汰最早调入的页面
2. 最近最久未使用算法LRU：算法赋予每个页面一个访问字段，用来记录上次页面被访问到现在所经历的时间t，每次置换的时候把t值最大的页面置换出去(实现方面可以采用寄存器或者栈的方式实现)
3. 时钟算法clock(也被称为是最近未使用算法NRU)：页面设置一个访问为，并将页面链接为一个环形队列，页面被访问的时候访问位设置为1。页面置换的时候，如果当前指针所指页面访问为为0，那么置换，否则将其置为0，循环直到遇到一个访问为位0的页面
4. 改进型Clock算法：在Clock算法的基础上添加一个修改位，替换时根究访问位和修改位综合判断。优先替换访问为何修改位都是0的页面，其次是访问位为0修改位为1的页面。
5. 最少使用算法LFU：设置寄存器记录页面被访问次数，每次置换的时候置换当前访问次数最少的。存在问题是该访问寄存器并不能真正反映当前页面访问次数，因为访问速度比较快，所以在更新寄存器的时间间隔内访问1次和访问100次都是一样的。另外，LFU和LRU是很类似的，支持硬件也是一样的，但是区分两者的关键在于一个以时间为标准，一个以次数为标准(例如对于寄存器 pa 001111 和pb 111000，两个页面，如果采用LRU，那么被淘汰的是pa，如果采用LFU那么被淘汰的是pb)。
6. 页面缓冲算法PBA：置换的时候，页面无论是否被修改过，都不被置换到磁盘，而是先暂留在内存中的页面链表(已修改页面链表和未修改页面链表，也可以不区分)里面，当其再次被访问的时候可以直接从这些链表中取出而不必进行磁盘IO，当链表中已修改也难数目达到一定数量之后，进行依次写磁盘操作(相当于将多次IO合并为一次)